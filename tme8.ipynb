{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ei9rT_XZ3SO5"
   },
   "source": [
    "### TME sur Echantillonage\n",
    "\n",
    "## Diffusion dans les graphes \n",
    "\n",
    "Au cours des vingt derni√®res ann√©es, les r√©seaux sociaux sont devenus un m√©dia d‚Äôinformation incontournable, mettant en jeu des dynamiques complexes de communication entre utilisateurs. La mod√©lisation de la diffusion d‚Äôinformation sur les r√©seaux constitue depuis lors un enjeu majeur, pour diverses t√¢ches\n",
    "telles que l‚Äôidentification de leaders d‚Äôopinions, la pr√©diction ou la maximisation de l‚Äôimpact d‚Äôun contenu diffus√©, la d√©tection de communaut√©s d‚Äôopinions, ou plus g√©n√©ralement l‚Äôanalyse des dynamiques du r√©seau consid√©r√©.\n",
    "\n",
    "Le mod√®le propos√© par (Saito et al, 2009) consid√®re une diffusion en cascade dans laquelle l'information transite de noeuds en noeuds du r√©seau en suivant des relations d'influence entre les utilisateurs. Lorsqu'un utilisateur est ``infect√©'' par une information, il poss√®de une chance unique de la retransmettre √† chacun de ses successeurs dans le graphe, selon une probabilit√© d√©finie sur le lien correspondant. Le mod√®le d√©finit en fait deux param√®tres sur chaque lien $(u,v)$ du graphe:\n",
    "\n",
    "\n",
    "*   $k_{u,v}$: la probabilit√© que l'utilisateur $u$ transmette une information diffus√©e √† $v$\n",
    "*   $r_{u,v}$: si la transmission s'effectue, l'utilisateur $v$ la re√ßoit au temps $t_v=t_u+\\delta$, avec $\\delta \\sim Exp(r_{u,v})$\n",
    "\n",
    "Pour utiliser ce mod√®le, on devra donc √©chantillonner selon la distribution exponentielle. Pour commencer, on cherche alors √† √©crire une m√©thode $exp(rate)$ qui √©chantillonne des variables d'une loi exponentielle selon le tableau d'intensit√©s $rate$ pass√© en param√®tre. Cet √©chantillonnage se fera par **Inverse Transform Sampling**. Pour √©viter les divisions par 0, on ajoutera $1e-200$ aux intensit√©s qui valent 0.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "f1aE9ijomC1j",
    "outputId": "80352e92-d353-4dad-fc36-daa80c92140e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.02011849 0.50670619 0.33095193]\n",
      " [0.24970305 0.20384465 0.16650975]]\n",
      "[[1.00356177 0.50416273 0.34028414]\n",
      " [0.25231623 0.20024732 0.16911951]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "def exp(rate):\n",
    "    \n",
    "    #Votre code ici\n",
    "    u=np.random.rand(*np.array(rate).shape)\n",
    "    return -np.log(u)/rate\n",
    "\n",
    "#Test\n",
    "a=exp(np.array([[1,2,3],[4,5,6]]))\n",
    "for i in range(10000):\n",
    "    a+=exp(np.array([[1,2,3],[4,5,6]]))\n",
    "print(a/10000)\n",
    "\n",
    "# Pour comparaison: \n",
    "a=np.random.exponential(1.0/np.array([[1,2,3],[4,5,6]]))\n",
    "for i in range(10000):\n",
    "    a+=np.random.exponential(1.0/np.array([[1,2,3],[4,5,6]]))\n",
    "print(a/10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHJPFXBKoqIf"
   },
   "source": [
    "Soit le graphe de diffusion donn√© ci dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBihGMdL7tZw"
   },
   "outputs": [],
   "source": [
    "\n",
    "names={0:\"Paul\",1:\"Jean\",2:\"Hector\",3:\"Rose\",4:\"Yasmine\",5:\"L√©o\",6:\"Amine\",7:\"Mia\",8:\"Quentin\",9:\"Gaston\",10:\"Louise\"}\n",
    "k={(0,1):0.9,(1,0):0.9,(1,2):0.2,(2,3):0.5,(3,2):0.4,(2,4):0.9,(4,3):0.9,(1,3):0.5,(2,5):0.5,(5,7):0.7,(1,6):0.2,(6,7):0.1,(1,8):0.8,(8,9):0.2,(1,10):0.5,(10,9):0.9,(8,1):0.8}\n",
    "r={(0,1):0.2,(1,0):3,(1,2):1,(2,3):0.2,(3,2):0.5,(2,4):10,(4,3):2,(1,3):2,(2,5):0.5,(5,7):15,(1,6):3,(6,7):4,(1,8):0.8,(8,9):0.1,(1,10):12,(10,9):1,(8,1):14}\n",
    "graph=(names,k,r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cx2XlKT97sbh"
   },
   "source": [
    "La fonction display_graph ci dessous permet de visualiser le graphe de diffusion correspondant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "M-etZqDj3PXW",
    "outputId": "e893e14e-84e1-4300-e798-6682770b3b3b"
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "style = { \"bgcolor\" : \"#6b85d1\", \"fgcolor\" : \"#FFFFFF\" }\n",
    "\n",
    "def display_graph ( graph_data, style, graph_name=\"diffusion_graph\" ):\n",
    "    graph = pydot.Dot( graph_name , graph_type='digraph')\n",
    "    names,k,r=graph_data\n",
    "    # cr√©ation des noeuds du r√©seau\n",
    "    for (i,name) in names.items():\n",
    "        new_node = pydot.Node( str(i)+\"_\"+name,\n",
    "                               style=\"filled\",\n",
    "                               fillcolor=style[\"bgcolor\"],\n",
    "                               fontcolor=style[\"fgcolor\"] )\n",
    "        graph.add_node( new_node )\n",
    "\n",
    "    # cr√©ation des arcs\n",
    "    for edge,valk in k.items():\n",
    "        valr=r[edge]\n",
    "        n1=str(edge[0])+\"_\"+names[edge[0]]\n",
    "        n2=str(edge[1])+\"_\"+names[edge[1]]\n",
    "        new_edge = pydot.Edge ( n1, n2, label=\"k=\"+str(valk)+\",r=\"+str(valr))\n",
    "        graph.add_edge ( new_edge )\n",
    "\n",
    "    # sauvegarde et affaichage\n",
    "    outfile = graph_name + '.png'\n",
    "    graph.write_png( outfile )\n",
    "    img = mpimg.imread ( outfile )\n",
    "    plt.imshow( img )\n",
    "display_graph(graph,style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0_Ol6AgQa9g"
   },
   "source": [
    "On souhaite √™tre capable d'estimer les probabilit√©s marginales d'infection des diff√©rents utilisateurs du r√©seau par une information pour laquelle on conna√Æt le d√©but de la diffusion. \n",
    "\n",
    "Pour cela, on consid√®re une liste d'infections qui correspond aux couples (utilisateur, temps d'infection) observ√©s pour cette diffusion pendant une p√©riode de temps initial. Par exemple la liste $infections=[(1,0),(4,1)]$ \n",
    "correspond √† une diffusion pour laquelle on a observ√© l'infection de l'utilisateur 1 au temps 0 et l'infection de l'utilisateur 4 au temps 1. \n",
    "\n",
    "Etant donn√©s les cycles possibles dans le graphe de diffusion, consid√©rer un calcul exact des probabilit√©s d'infection des diff√©rents utilisateurs sachant le d√©but de la diffusion est inenvisageable : il faudrait consid√©rer toutes les combinaisons possibles (infinies) de temps d'infection pour tous les utilisateurs non observ√©s dans la p√©riode initiale. \n",
    "\n",
    "Une possibilit√© pour calculer ces probabilit√©s d'infections est de travailler par √©chantillonnage de Monte Carlo: on r√©alise $n$ tirages d'infections connaissant le d√©but de la diffusion et on recense le ratio des simulations dans lesquelles chacun des utilisateurs est infect√© avant un temps $maxT$.  \n",
    "\n",
    "L'id√©e est alors dans un premier temps d'√©crire une m√©thode $simulation(graph,infections,max\\_obs)$ qui, √† partir d'une liste d'infections initiales et d'un temps d'observation maximal $max\\_obs$, retourne les temps d'infection de l'ensemble des noeuds en fin de diffusion, sous la forme d'un tableau o√π chaque case $i$ contient le temps d'infection du noeud $i$. Si le noeud $i$ n'a pas √©t√© infect√© ou bien si il l'a √©t√© apr√®s un temps maximal $maxT$, la case $i$ contient alors la valeur $maxT$. \n",
    "\n",
    "\n",
    "Le pseudo-code de la m√©thode de simulation est donn√© ci dessous, avec $t_i$ le temps d'infection courant du noeud $i$:\n",
    "```\n",
    "ti=maxT pour tout i non infect√© dans la liste initiale\n",
    "Tant qu'il reste des infectieux dont le temps est < maxT:\n",
    "  i=Infectieux de temps d'infection minimal\n",
    "  Pour tout noeud j tel que tj>ti:\n",
    "    sampler x selon P(i->j|ti,tj>max_obs)\n",
    "    si x==1:\n",
    "       sampler delta selon Exp(rij)\n",
    "       t=ti+delta\n",
    "       si ti<max_obs: t+=max_obs-ti (c'est en fait une exponentielle tronqu√©e √† gauche, d'o√π la translation)  \n",
    "       si t<tj: tj=t \n",
    "  Retrait de i de la liste des infectieux\n",
    "```\n",
    "o√π $P(i\\rightarrow j|t_i,t_j>max\\_obs)$ correspond √† la probabilit√© que $i$ transmette l'information √† $j$ (quel que soit le temps d'infection) sachant qu'il ne l'a pas infect√© avant $max\\_obs$:\n",
    "$P(i\\rightarrow j|t_i,t_j>max\\_obs)=\\begin{cases} k_{i,j} \\text{ si } t_i\\geq max\\_obs, \\\\ \\dfrac{k_{i,j} exp(-r_{i,j}(max\\_obs-t_i))}{k_{i,j} exp(-r_{i,j}(max\\_obs-t_i)) + 1 - k_{i,j} } sinon. \\end{cases}$\n",
    "\n",
    "Compl√©tez le code de la fonction donn√©e ci-dessous: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "FgfnYxbNTGDa",
    "outputId": "7b487aaa-f4ab-4887-ba7c-b622a93daf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.          1.          1.50623057  1.42941815 10.          6.38695469\n",
      "  1.27549308  6.39916656  1.04626735 10.         10.        ]\n",
      "[ 0.          1.          1.02161356  1.38665897  1.10964273  1.53337661\n",
      "  1.71158257  1.5655004  10.         10.         10.        ]\n",
      "[ 0.          1.          1.05789601  1.51150956  1.14031241 10.\n",
      "  1.12002156 10.         10.          3.08180821  1.03329383]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "maxT=10\n",
    "def simulation(graph,infections,max_obs):\n",
    "    names,gk,gr=graph\n",
    "    nbNodes=len(names)\n",
    "    \n",
    "    #au d√©part,on suppose que tous les noeuds ont le temps maximal √† s'infecter \n",
    "    #(ti=maxT pour tout i non infect√© dans la liste initiale)\n",
    "    \n",
    "    \n",
    "    \n",
    "    infectious=np.array([maxT]*nbNodes,dtype=float)\n",
    "    #liste des ids et liste des temps (zip pour parcourir,  puis appliquer array grace √† map)\n",
    "    ids,t=map(np.array,zip(*infections))\n",
    "    \n",
    "    #retourne les ids dont t est inferieur √† max_obs\n",
    "    ids=ids[t<=max_obs]\n",
    "    #retourne les t dont t inferieur √† t\n",
    "    t=t[t<=max_obs]\n",
    "    #changer les valeurs des infectious o√π t<=max_obs\n",
    "    infectious[ids]=t\n",
    "    times=np.copy(infectious)\n",
    "    inf=np.copy(infectious)\n",
    "    \n",
    "\n",
    "    #Tant qu'il reste des infectieux dont le temps est < maxT:\n",
    "    while np.any([infectious<maxT]):\n",
    "        \n",
    "        #i=Infectieux de temps d'infection minimal\n",
    "        i = np.argmin(infectious)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Pour tout noeud j tel que tj>ti:\n",
    "        for j in range(0,len(times)):\n",
    "            if(times[j] > times[i]):\n",
    "                if(not(i,j) in gr.keys()): \n",
    "                    x = 0\n",
    "                else:    \n",
    "                    #sampler x selon P(i->j|ti,tj>max_obs)\n",
    "                    x = P(i,j,graph,times,max_obs)\n",
    "\n",
    "                # si x==1:\n",
    "                if(x == 1):\n",
    "                    # sampler delta selon Exp(rij)\n",
    "                    rij = graph[2].get((i,j),0)\n",
    "                    delta = exp([[rij]])[0]\n",
    "                    # t=ti+delta\n",
    "                    t = times[i] + delta\n",
    "                    # si ti<max_obs: t+=max_obs-ti (c'est en fait une exponentielle tronqu√©e √† gauche, d'o√π la translation)    \n",
    "                    if(times[i] < max_obs):\n",
    "                        t+=max_obs-times[i]\n",
    "                    # si t<tj: tj=t \n",
    "                    if(t<times[j]):\n",
    "                        times[j] = t\n",
    "                        infectious[j] = t\n",
    "\n",
    "        #Retrait de i de la liste des infectieux\n",
    "        infectious[i] = np.inf # (ne plus le considerer au lieu de le supprimer, condition de boucle au d√©but)\n",
    "\n",
    "    \n",
    "    return(times)        \n",
    "        \n",
    "\n",
    "#ùëÉ(ùëñ‚Üíùëó|ùë°ùëñ,ùë°ùëó>ùëöùëéùë•_ùëúùëèùë†)  correspond √† la probabilit√© que ùëñ transmette l'information √† ùëó (quel que soit le temps d'infection) sachant qu'il ne l'a pas infect√©    \n",
    "def P(i,j,graph,times,max_obs):\n",
    "    names,gk,gr=graph\n",
    "\n",
    "    #ne pas considerer \n",
    "    if(not (i,j) in gr.keys()):\n",
    "        return 0\n",
    "    \n",
    "    #depasser le temps d'observation\n",
    "    if(times[i] > max_obs):\n",
    "        \n",
    "        # tirer une valeur al√©atoirement (chances de transmission).\n",
    "        x = np.random.rand()\n",
    "        \n",
    "        if(x > gk[(i,j)]):\n",
    "            return 0 #arc non utilis√©\n",
    "        else :\n",
    "            return 1 #arc utilis√©\n",
    "    else:\n",
    "        \n",
    "        x = np.random.rand()\n",
    "        \n",
    "        if x > (gk[(i,j)]*np.exp(-gr[(i,j)]*(max_obs-times[i])))/(gk[(i,j)]*np.exp(-gr[(i,j)]*(max_obs-times[i]))+1-gk[(i,j)]):\n",
    "            return 1\n",
    "        else :\n",
    "            return 0    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(simulation(graph,[(0,0)],0))\n",
    "np.random.seed(0)\n",
    "print(simulation(graph,[(0,0)],2))\n",
    "np.random.seed(0)\n",
    "print(simulation(graph,[(0,0),(1,1)],1))\n",
    "print(simulation(graph,[(0,0),(1,1)],1))\n",
    "print(simulation(graph,[(0,0),(1,1)],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPpzbeS_UMXk"
   },
   "source": [
    "La m√©thode $getProbaMC(graph,infections,max\\_obs,nbsimu)$ retourne les estimations de probabilit√©s marginales d'infection des diff√©rents utilisateurs de $graph$, conditionn√©es √† l'observation des infections de la liste $infections$ pendant les $max\\_obs$ premiers jours de diffusion. Pour √™tre enregistr√©e, une infection doit intervenir avant la seconde $maxT$. Ainsi, si la m√©thode retourne 0.2 pour le noeud $i$, cela indique qu'il a √©t√© infect√© avec un temps $t_i \\in ]max\\_obs,maxT[$ dans 20% des $nbsimu$ simulations effectu√©es. Compl√©ter la m√©thode ci dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "dV9zdHYPG7Op",
    "outputId": "d75fd0eb-e153-4a40-ebc7-409133a2161b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.      0.08744 0.02864 0.05014 0.02533 0.01181 0.01711 0.00991 0.06634\n",
      " 0.04146 0.04432]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def getProbaMC(graph,infections,max_obs,nbsimu=100000):\n",
    "    names,gk,gr=graph\n",
    "    nbNodes=len(names)\n",
    "    rInf=np.array([0]*nbNodes)\n",
    "    #>>>>>>>>>>>\n",
    "    \n",
    "    #lancer la simulation  nbsimu fois\n",
    "    for i in range(nbsimu): \n",
    "        times = simulation(graph, infections, max_obs) \n",
    "        for node in range(nbNodes): \n",
    "            if times[node] < maxT and times[node] > max_obs: # si ùë°ùëñ‚àà]ùëöùëéùë•_ùëúùëèùë†,ùëöùëéùë•ùëá[ \n",
    "                rInf[node]+= 1 #compter le nombre de fois\n",
    "    rInf = rInf/nbsimu #proba\n",
    "        \n",
    "    #<<<<<<<<<<<\n",
    "    return (rInf)\n",
    "\n",
    "rInf=getProbaMC(graph,[(0,0)],0)\n",
    "print(rInf)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-sluTACtRCM"
   },
   "source": [
    "Cette m√©thode permet de bonnes estimations (malgr√© une certaine variance) lorsque l'on n'a pas d'observations autres que le vecteur d'infections initiales (i.e., on estime des probabilit√©s de la forme: $P(t_i < maxT|\\{t_j\\leq max\\_obs\\})$). Par contre, si l'on souhaite obtenir des probabilit√©s d'infection du type $P(t_i < maxT|\\{t_j\\leq max\\_obs\\}, \\{t_j, j \\in {\\cal O}\\})$, c'est √† dire conditionn√©es √† des observations suppl√©mentaires pour un sous-ensembles de noeuds ${\\cal O}$ (avec $t_j > max\\_obs$ pour tout noeud de ${\\cal O}$), l'utilisation de la m√©thode de MonteCarlo pr√©c√©dente est impossible. Cela impliquerait de filtrer les simulations obtenues selon qu'elles remplissent les conditions sur les noeuds de ${\\cal O}$, ce qui nous am√®nerait √† toutes les √©carter sachant que l'on travaille avec des temps continus. \n",
    "\n",
    "Pour estimer ce genre de probabilit√© conditionnelle, nous allons nous appuyer sur des m√©thodes de type MCMC, notamment la m√©thode de Gibbs Sampling. Cette m√©thode est utile pour simuler selon une loi jointe, lorsqu'il est plus simple d'√©chantillonner de chaque variable conditionnellement √† toutes les autres plut√¥t que directement de cette loi jointe. L'algorithme est donn√© par: \n",
    "\n",
    "\n",
    "1.   Tirage d'un vecteur de valeurs initiales pour toutes les variables $X_i$\n",
    "2.   Pour toutes les variable $X_i$ choisies dans un ordre al√©atoire, √©chantillonnage d'une nouvelle valeur: $X_i \\sim p(x_i\\mid x_1,\\dots,x_{i-1},x_{i+1},\\dots,x_n)$\n",
    "3.   Recommencer en 2 tant qu'on souhaite encore des √©chantillons\n",
    "\n",
    "Notons qu'il est souvent utile d'exploiter la relation suivante, qui indique que pour √©chantillonner de la loi conditionnelle, il suffit d'√©chantillonner chaque variable proportionnellement √† la loi jointe, avec toutes les autres variables fix√©es: \n",
    "$$p(x_j\\mid x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n) = \\frac{p(x_1,\\dots,x_n)}{p(x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n)} \\propto p(x_1,\\dots,x_n)$$\n",
    "\n",
    "Apr√®s une p√©riode dite de $Burnin$ d'un nombre d'√©poques √† d√©finir, l'algorithme √©met des √©chantillons qui suivent la loi jointe connaissant les observations. Lorsque l'objectif est d'estimer des probabilit√©s marginales, on fait alors tourner cet algorithme pendant une certain nombre d'√©poques apr√®s la p√©riode de $Burnin$, au cours desquelles on recence les diff√©rentes affectations de chacune des variables √©tudi√©es. \n",
    "\n",
    "Pour mettre en oeuvre cet algorithme, nous aurons aurons besoin d'avoir acc√®s rapidement aux pr√©decesseurs et successeurs dans le graphe. La m√©thode ci-dessous retourne un couple de dictionnaires √† partir du graphe: \n",
    " \n",
    "\n",
    "*   $preds[i]$  contient la liste des pr√©d√©cesseurs du  noeud $i$, sous la forme d'une liste de triplets $(j,k_{j,i},r_{j,i})$ pour tous les $j$ pr√©c√©dant $i$ dans le graphe.    \n",
    "*   $succs[i]$  contient la liste des successeurs du  noeud $i$, sous la forme d'une liste de triplets $(j,k_{i,j},r_{i,j})$ pour tous les $j$ point√©s par $i$ dans le graphe.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "0sPmzchnSP3r",
    "outputId": "e2b24d9c-1efb-479c-b56d-88652ed68a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds= {1: [(0, 0.9, 0.2), (8, 0.8, 14)], 0: [(1, 0.9, 3)], 2: [(1, 0.2, 1), (3, 0.4, 0.5)], 3: [(2, 0.5, 0.2), (4, 0.9, 2), (1, 0.5, 2)], 4: [(2, 0.9, 10)], 5: [(2, 0.5, 0.5)], 7: [(5, 0.7, 15), (6, 0.1, 4)], 6: [(1, 0.2, 3)], 8: [(1, 0.8, 0.8)], 9: [(8, 0.2, 0.1), (10, 0.9, 1)], 10: [(1, 0.5, 12)]}\n",
      "succs= {0: [(1, 0.9, 0.2)], 1: [(0, 0.9, 3), (2, 0.2, 1), (3, 0.5, 2), (6, 0.2, 3), (8, 0.8, 0.8), (10, 0.5, 12)], 2: [(3, 0.5, 0.2), (4, 0.9, 10), (5, 0.5, 0.5)], 3: [(2, 0.4, 0.5)], 4: [(3, 0.9, 2)], 5: [(7, 0.7, 15)], 6: [(7, 0.1, 4)], 8: [(9, 0.2, 0.1), (1, 0.8, 14)], 10: [(9, 0.9, 1)]}\n"
     ]
    }
   ],
   "source": [
    "def getPredsSuccs(graph):\n",
    "    names,gk,gr=graph\n",
    "    nbNodes=len(names)\n",
    "    preds={}\n",
    "    succs={}\n",
    "    for (a,b),v in gk.items():\n",
    "        s=succs.get(a,[])\n",
    "        s.append((b,v,gr[(a,b)]))\n",
    "        succs[a]=s\n",
    "        p=preds.get(b,[])\n",
    "        p.append((a,v,gr[(a,b)]))\n",
    "        preds[b]=p\n",
    "    return (preds,succs)\n",
    "preds,succs=getPredsSuccs(graph)\n",
    "print(\"preds=\",preds)\n",
    "print(\"succs=\",succs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vk-vCmVX6HtV"
   },
   "source": [
    "Pour calculer les probabilit√©s conditionnelles, il faut prendre en compte les quantit√©s suivantes: \n",
    "\n",
    "\n",
    "*   Probabilit√© pour $j$ d'√™tre infect√© par $i$ au temps $t_j$ connaissant $t_i < t_j$:  \n",
    "$$\\alpha_{i,j}=k_{i,j}r_{i,j} exp(-r_{i,j}(t_j-t_i))$$\n",
    "*   Probabilit√© pour $j$ de ne pas √™tre infect√© par $i$ jusqu'au temps $t$:\n",
    "$$\\beta_{i,j}=k_{i,j} exp(-r_{i,j}(t_j-t_i)) + 1 - k_{i,j}$$\n",
    "*   Probabilit√© pour $j$ d'√™tre infect√© au temps $t_j$ connaissant les pr√©decesseurs infect√©s avant $t_j$:\n",
    "$$h_{j}=\\prod_{i \\in preds[j], t_i<t_j} \\beta_{i,j} \\sum_{i \\in preds[i], t_i<t_j} \\alpha_{i,j} / \\beta_{i,j}$$\n",
    "*   Probabilit√© pour $j$ de ne pas √™tre infect√© avant $t_j=maxT$ connsaissant ses pr√©decesseurs infect√©s:\n",
    "$$g_{j}=\\prod_{i \\in preds[j], t_i<t_j} \\left(k_{i,j} exp(-r_{i,j}(maxT-t_i)) + 1 - k_{i,j}\\right)=\\prod_{i \\in preds[j], t_i<t_j} \\beta_{i,j}$$\n",
    "\n",
    "A noter que pour tout $i$ tel que $t_i< max\\_obs$, on prend $\\frac{\\alpha_{i,j}}{k_{i,j} exp(-r_{i,j}(max\\_obs-t_i))}$ et $\\frac{\\beta_{i,j}}{k_{i,j} exp(-r_{i,j}(max\\_obs-t_i))}$  dans les d√©finitions de $h_j$ et $g_j$ (donc dans le calcul de la variable $b$ dans la m√©thode ci-dessous). \n",
    "\n",
    "\n",
    "Dans la m√©thode $computeab(v, times, preds, max\\_obs)$, on pr√©pare le calcul et les mises √† jour de ces quantit√©s. La m√©thode calcule, pour un noeud $v$ selon les temps d'infection courants donn√©s dans $times$, deux quantit√©s $a$ et $b$: \n",
    "*   $a= max(1e^{-20}, \\sum_{i \\in preds[v], t_i<t_v} \\alpha_{i,v} / \\beta_{i,v})$ si $t_v< maxT$ et $a=1$ sinon. \n",
    "\n",
    "*   $b=\\sum_{i \\in preds[v], t_i<t_v} \\log \\beta_{i,v}$.\n",
    "\n",
    "Pour les noeuds $i$ tels que $t_i< max\\_obs$, $a=1$ et $b=0$. \n",
    "\n",
    "Compl√©ter la m√©thode $computeab$ donn√©e ci-dessous:   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "cOnGCJCBSulp",
    "outputId": "c372babf-0b65-425f-e46c-5ed060e5c8c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0)\n",
      "(1, 0)\n",
      "(0.17610107365772137, -0.17810126145719926)\n",
      "(1, 0)\n",
      "(0.012293749653343879, -0.21077360840944234)\n",
      "(0.012293749653343879, -0.07561333357263278)\n",
      "(1, 0)\n",
      "(1, 0)\n"
     ]
    }
   ],
   "source": [
    "eps=1e-20\n",
    "\n",
    "def alpha(i,j,kij,rij,t):\n",
    "    return kij*rij*np.exp(-rij*(t[j]-t[i]))\n",
    "\n",
    "def beta(i,j,kij,rij,t):\n",
    "    return kij*np.exp(-rij*(t[j]-t[i]))+1-kij\n",
    "\n",
    "def beta2(i,j,kij,rij,t,max_obs): #gerer le cas ti < max_Obs\n",
    "    return kij*np.exp(-rij*(max_obs-t[i]))+1-kij\n",
    "\n",
    "def computeab(v, times, preds, max_obs):\n",
    "    preds=preds.get(v,[]) #avoir les pr√©d√©cesseur du noeud v\n",
    "    t=times[v] #avoir le temps de v\n",
    "    if t<=max_obs: #si v infect√©\n",
    "        return (1,0)\n",
    "    a = eps\n",
    "    b=0\n",
    "    \n",
    "    #si v a des pr√©d√©cesseurs\n",
    "    if len(preds)>0: \n",
    "        #>>>>>>>>>>>>>\n",
    "        if(t<maxT): #si son t <maxT\n",
    "            sum_alpha = 0\n",
    "            for ind in range(len(preds)):\n",
    "                (i,kiv,riv) = preds[ind]\n",
    "                if(times[i] <t ):\n",
    "                    sum_alpha += alpha(i,v,kiv,riv,times)/beta(i,v,kiv,riv,times)\n",
    "                    if(times[i]<max_obs):\n",
    "                        b+= np.log(beta(i,v,kiv,riv,times)) - np.log(beta2(i,v,kiv,riv,times,max_obs))\n",
    "                    else:\n",
    "                        b+= np.log(beta(i,v,kiv,riv,times))\n",
    "            a = max(eps, sum_alpha)\n",
    "        else:\n",
    "            a = 1\n",
    "\n",
    "        #<<<<<<<<<<<<\n",
    "    return (a,b)\n",
    "\n",
    "nbNodes=len(graph[0])\n",
    "times=np.array([maxT]*nbNodes,dtype=float)\n",
    "times[0]=0\n",
    "times[1]=1\n",
    "times[2]=4\n",
    "#times[3]=10\n",
    "\n",
    "\n",
    "print(computeab(0,times,preds,max_obs=0))\n",
    "print(computeab(0,times,preds,max_obs=2))\n",
    "print(computeab(1,times,preds,max_obs=0))\n",
    "print(computeab(1,times,preds,max_obs=2))\n",
    "print(computeab(2,times,preds,max_obs=0))\n",
    "print(computeab(2,times,preds,max_obs=2))\n",
    "print(computeab(3,times,preds,max_obs=0))\n",
    "print(computeab(3,times,preds,max_obs=2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aXnKXCMfLMK-"
   },
   "source": [
    "La m√©thode $computell$ calcule la log-vraisemblance d'une diffusion (repr√©sent√©e par le tableau times), en appelant la m√©thode computeab sur l'ensemble des noeuds du r√©seau. Elle retourne un triplet (log-likelihood, sa, sb), avec $sa$ et $sb$ les tables des valeurs $a$ et $b$ pour tous les noeuds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "aM0K-VhPUXJn",
    "outputId": "0d61f9f9-4734-4200-b350-393dce314798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll= -6.524236340526027\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "like_indiv= [1.         0.14737154 0.00995741 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "def computell(times,preds,max_obs):\n",
    "  #>>>>>>\n",
    "  \n",
    "    sa = []\n",
    "    sb = []\n",
    "    for v in range(len(times)) :\n",
    "        a,b = computeab(v,times,preds,max_obs)\n",
    "        sa.append(a)\n",
    "        sb.append(b)\n",
    "\n",
    "    ll = np.sum(np.log(sa)+sb)\n",
    "    return ll,sa,sb\n",
    "    \n",
    "  #<<<<<\n",
    "\n",
    "ll,sa,sb=computell(times,preds,max_obs=0)\n",
    "print(\"ll=\",ll)\n",
    "print(times)\n",
    "print(\"like_indiv=\",np.exp(np.log(sa)+sb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNlDzJeFNb60"
   },
   "source": [
    "Afin de pr√©parer les mises √† jour lors des affectations successives des variables du Gibbs Sampling, on propose de d√©finir une m√©thode $removeV(v,times,succs,sa,sb)$ qui retire temporairement du r√©seau un noeud $v$, en passant son temps d'infection √† -1 dans times et en retirant sa contribution aux valeurs a et b (contenues dans sa et sb) de tous ses successeurs $j$ tels que $t_j > t_v$ (y compris donc les non infect√©s qui sont √† $t_j=maxT$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "rEGzpS_DaRX5",
    "outputId": "1ff8cc3b-3074-4606-bc73-f5af6e753687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa= [1, 0.17610107365772137, 0.012293749653343879, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "sb= [0, -0.17810126145719926, -0.21077360840944234, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "diffa= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "diffb= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "diffa= [ 0.          0.82389893 -0.01229375  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "diffb= [0.         0.17810126 0.21077361 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "def removeV(v,times,succs,sa,sb):\n",
    "  succs=succs.get(v,[])\n",
    "  t=times[v]\n",
    "  if t<0:\n",
    "    return \n",
    "  times[v]=-1\n",
    "  sa[v]=1.0\n",
    "  sb[v]=0.0\n",
    "  if len(succs)>0:\n",
    "    c,k,r=map(np.array,zip(*succs))\n",
    "    tp=times[c]\n",
    "    which=(tp>t)\n",
    "\n",
    "    tp=tp[which]\n",
    "    dt=tp-t\n",
    "    k=k[which]\n",
    "    r=r[which]\n",
    "    c=c[which]\n",
    "    rt = -r*dt\n",
    "    b1=k*np.exp(rt)\n",
    "    b=b1+1.0-k\n",
    "    \n",
    "    a=r*b1\n",
    "    a=a/b\n",
    "    b=np.log(b)\n",
    "    \n",
    "    sa[c]=sa[c]-np.where(tp<maxT,a,0.0)\n",
    "    sa[c]=np.where(sa[c]>eps,sa[c],eps)\n",
    "    sb[c]=sb[c]-b\n",
    "    sb[c]=np.where(sb[c]>0,0,sb[c])\n",
    "\n",
    "\n",
    "#Test\n",
    "print(\"sa=\",sa)\n",
    "print(\"sb=\",sb)\n",
    "\n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "ntimes=np.copy(times)\n",
    "removeV(3,ntimes,succs,nsa,nsb)\n",
    "print(\"diffa=\",nsa-sa)\n",
    "print(\"diffb=\",nsb-sb)\n",
    "\n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "ntimes=np.copy(times)\n",
    "removeV(1,ntimes,succs,nsa,nsb)\n",
    "print(\"diffa=\",nsa-sa)\n",
    "print(\"diffb=\",nsb-sb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cb8iIMwgO6D9"
   },
   "source": [
    "La m√©thode addVatT fait l'inverse: elle rajoute un noeud qui √©tait retir√© du r√©seau, avec un temps $newt$. Il faut alors mettre √† jour les valeurs a et b (dans sa et sb) de tous les successeurs de $v$ tels que $t_j > newt$ et calculer les valeurs a et b du noeud v. \n",
    "\n",
    "Compl√©ter le code ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "9sDiLiXnngog",
    "outputId": "9ffa4642-7677-45ef-c2bf-2bb6df8b0cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014674393432211837 9.999999999999992e-21 9.999999999999992e-21 -46.051701859880914\n",
      "1.0 1.0 1.0 -46.051701859880914\n",
      "1.0 1.0 1.0 -46.051701859880914\n"
     ]
    }
   ],
   "source": [
    "def addVatT(v,times,newt,preds,succs,sa,sb,max_obs):\n",
    "  t=times[v]\n",
    "  if t>=0:\n",
    "    raise Error(\"v  must have been removed before\")\n",
    "  \n",
    "  #>>>>>>>>>>>>\n",
    "    times[v] = newt\n",
    "    sa[v],sb[v] = computeab(v, times, preds, max_obs)\n",
    "    for i in range(0,len(times)):\n",
    "        if(times[i]>newt):\n",
    "            sa[i],sb[i] = computeab(i, times, preds, max_obs)\n",
    "  #<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Tests: \n",
    "   \n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "c,_,_=map(np.array,zip(*succs[1]))\n",
    "c=np.append(c,1)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(1,times,succs,nsa,nsb)\n",
    "addVatT(1,times,2,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(1,times,succs,nsa,nsb)\n",
    "addVatT(1,times,1,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "c,_,_=map(np.array,zip(*succs[0]))\n",
    "c=np.append(c,0)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(0,times,succs,nsa,nsb)\n",
    "addVatT(0,times,maxT,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(0,times,succs,nsa,nsb)\n",
    "addVatT(0,times,0,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "c,_,_=map(np.array,zip(*succs[5]))\n",
    "c=np.append(c,5)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(5,times,succs,nsa,nsb)\n",
    "addVatT(5,times,1,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(5,times,succs,nsa,nsb)\n",
    "addVatT(5,times,maxT,preds,succs,nsa,nsb,max_obs=0)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3isBRUNi3JPA"
   },
   "source": [
    "Pour √©chantillonner pour une variable $i$, il faudra √™tre √† m√™me de comparer les vraisemblances selon les diff√©rentes affectations. Cela implique de calculer la somme de toutes ces vraisemblances. Mais pour r√©aliser cette somme, il faudrait que nous sortions de la repr√©sentation logarithmique: $\\sum_{t_i} exp(log(p(t_1,\\dots,t_i,\\dots,t_n))$. Si on le fait de cette mani√®re, on risque d'avoir des arrondis √† 0 presque partout. Une possibilit√© (log-sum-exp trick) est d'exploiter la relation suivante:  \n",
    "\n",
    "$$\\log\\sum_i x_i = x^* + \\log\\left( \\exp(x_1-x^*)+ \\cdots + \\exp(x_n-x^*) \\right)$$\n",
    "avec $x^* = \\max{\\{x_1, \\dots, x_n\\}}$\n",
    "\n",
    "Compl√©ter la m√©thode logsumexp suivante, qui r√©alise cette somme en √©vitant les probl√®mes num√©riques: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SZuOJI7B3p0O",
    "outputId": "3abe4a23-8999-4612-b06b-ab6b4557f0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.54045945 -0.67334455] [-3.54045945 -0.67334455]\n"
     ]
    }
   ],
   "source": [
    "def logsumexp(x,axis=-1):\n",
    "  #>>>>>>>>>>\n",
    "    star = np.max(x)\n",
    "    x = star + np.log(np.sum([np.exp(x[i]-star) for i in range(len(x))], axis))  \n",
    "  #<<<<<<<<<<\n",
    "    return x\n",
    "  \n",
    "\n",
    "#Test: \n",
    "x=np.array([[0.001,0.02,0.008],[0.1,0.01,0.4]])\n",
    "r=np.log(np.sum(x,-1))\n",
    "x=np.log(x)\n",
    "r2=logsumexp(x)\n",
    "print(r2,r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqVI0e9T85x-"
   },
   "source": [
    "On souhaite maintenant mettre en place une m√©thode $sampleV(v,times,newt,preds,succs,sa,sb,max\\_obs,k,k2)$ qui sample un nouveau temps d'infection pour le noeud $v$, connaissant les temps de tous les autres noeuds dans $times$ (ainsi que leurs valeurs $a$ et $b$ correspondantes contenues dans sa et sb). Puisque le domaine de support de $t_v$ est continu, on doit faire quelques approximations en se basant sur une discr√©tisation des valeurs possibles:\n",
    "\n",
    "\n",
    "1.   On √©chantillonne $k$ points $d_1,\\dots,d_k$ entre $max\\_obs$ et $maxT$ de mani√®re uniforme, que l'on ordonne de mani√®re croissante. On ajoute $t_v$ √† cet ensemble de points pour gagner en stabilit√© (ins√©r√© dans la liste de mani√®re √† conserver l'ordre croissant).   \n",
    "2.   On consid√®re chaque point $d_i$ comme le centre d'un bin $[(d_i+d_{i-1})/2,(d_i+d_{i+1})/2]$. Pour $d_1$ on prend $[max\\_obs,(d_i+d_{i+1})/2]$ et pour $d_k$ on prend   $[(d_i+d_{i-1})/2,maxT]$. On fait l'hypoth√®se que la densit√© de probabilit√© est constante sur l'ensemble du bin, que l'on √©value en son centre.   La probabilit√© que l'on √©chantillonne dans le bin $i$ est alors √©gale √†: $\\frac{z_i \\times l_i}{\\sum_j z_j \\times l_j + p_{maxT}}$, avec $z_i$ la densit√© calcul√©e en $d_i$, $l_i$ la taille du bin $i$ et $p_{maxT}$ la probabilit√© calcul√©e pour $maxT$ (i.e., la probabilit√© que $v$ ne soit pas infect√© dans la diffusion)\n",
    "3.  Si l'indice $i$ sampl√© de mani√®re proportionnelle aux probabilit√©s calcul√©es √† l'√©tape pr√©c√©dente n'est pas celui de $maxT$, $v$ est alors infect√© √† un temps inclus dans l'intervale du bin correspondant. Il s'agit alors de re-√©chantillonner $k2$ points uniform√©ment dans ce bin et de calculer les densit√©s en ces points (pour gagner en stabilit√© on ajoute le centre du bin $d_i$). Le nouveau temps de $v$ est alors √©chantillonn√© proportionnellement √† ces densit√©s.\n",
    "\n",
    "Compl√©ter le code ci-dessous:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "K3QmBCRbhkLM",
    "outputId": "766a0e1c-a19a-4c77-e930-852e6493e5d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[ 0.          1.          4.         10.         10.          4.20931617\n",
      " 10.         10.         10.         10.         10.        ]\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "  \n",
    "def sampleV(v,times,preds,succs,sa,sb,max_obs,k,k2):\n",
    "  #>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "  #Votre code ici\n",
    "  #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "  \n",
    "  \n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,0,10,10)\n",
    "print(times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCdSA3NF8CrE"
   },
   "source": [
    "Compl√©ter la m√©thode de Gibbs Sampling $gb$ ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsnQHVcdjfVT"
   },
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "def gb(graph,infections,max_obs,burnin=1000,nbEpochs=10000,k=100,k2=50,freqRecord=1):\n",
    "   #>>>>>>>>>>>>>>>>>>>>>>>\n",
    "   #Votre code ici\n",
    "   #>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "   return rate\n",
    "\n",
    "rate=gb(graph,[(0,0)],0)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iqx6CQ4vQ8rr"
   },
   "source": [
    "# Partie optionnelle\n",
    "\n",
    "L'algorithme de Metropolis-Hasting est une autre m√©thode de type MCMC qui utilise une distribution d'√©chantillonnage pour se d√©placer dans l'espace des points consid√©r√©s. Il s'agit de d√©finir une distribution $q(y_{t+1}|x_t)$ de laquelle on sait g√©n√©rer un d√©placement. L'algorithme proc√©de alors de la mani√®re suivante: \n",
    "\n",
    "\n",
    "1.   G√©n√©rer $y_{t+1}$ selon $q(y_{t+1}|x_t)$ \n",
    "2.   Calculer la probabilit√© d‚Äôacceptation $\\alpha(x_t,y_{t+1})=\\min\\left\\{\\frac{\\pi(y_{t+1})q(x_t,y_{t+1})}{\\pi(x_t)q(y_{t+1},x_t)},1\\right\\} \\,\\!, \\text{ avec } \\pi(x_t) \\text{ la densit√© de probabilit√© de } x_t$\n",
    "3.   Prendre $x_{t+1}=\\begin{cases} y_{t+1}, & \\text{avec probabilit√©}\\,\\,\\alpha \\\\ x_t, & \\text{avec probabilit√©}\\,\\,1-\\alpha \\end{cases}$\n",
    "\n",
    "\n",
    "\n",
    "Dans notre cas, on propose de travailler avec des d√©placements correspondants √† des permutations d'un temps d'infection √† chaque it√©ration, comme dans le cadre du Gibbs Sampling. A chaque √©tape on choisit donc une variable √† modifier, on choisit un nouveau temps pour cette variable et on calcule la densit√© correspondante. La probabilit√© d'acceptation est ensuite calcul√©e selon cette densit√© et la probabilit√© du d√©placement selon la distribution $q$ qui a servi √† g√©n√©rer le nouveau temps d'infection. On se propose de choisir $maxT$ avec une probabilit√© de 0.1. La probabilit√© $q(t_v|t)$ pour $t< maxT$ est alors √©gale  √†  $0.9\\times \\frac{1}{maxT-max\\_obs}$.\n",
    "\n",
    "Impl√©menter l'approche d'√©chantillonnage par Metropolis-Hasting pour notre probl√®me d'estimation de probabilit√©s marginales d'infection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGoHITZmGxg-"
   },
   "outputs": [],
   "source": [
    "#Votre code ici"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tme8_mapsi_2019",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
